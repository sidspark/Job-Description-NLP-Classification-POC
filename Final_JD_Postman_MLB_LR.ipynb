{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31b1f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\XZ221DR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\XZ221DR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\XZ221DR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import joblib\n",
    "import pickle\n",
    "import flask\n",
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "import sqlite3\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f6a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating Flask -----------------------------------------------------------------------\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da77cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading saved ML files ------------------------------------------------------------------\n",
    "tfidf_vectorizer = pickle.load(open(\"Save Model Files/vectorizerJD_POC_V01.pickle\", \"rb\"))\n",
    "multilabel_binarizer = pickle.load(open(\"Save Model Files/multilabel_binarizerJD_POC_V01.pickle\", \"rb\"))\n",
    "loaded_model = joblib.load('Save Model Files/JDClassificationPOC_V01.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f5f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting -------------------------------------------------------------------------------\n",
    "def infer_tags(q, tfidf_vectorizer):\n",
    "    q = clean_text(q)\n",
    "    q = remove_stopwords(q)\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    q_pred = loaded_model.predict(q_vec)\n",
    "\n",
    "    lt = multilabel_binarizer.inverse_transform(q_pred)\n",
    "\n",
    "    out = [item for t in lt for item in t]\n",
    "\n",
    "    return out\n",
    "\n",
    "#Clean text -------------------------------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe\n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    # remove everything alphabets\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "    # remove whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #lemmatizer\n",
    "    wordnet_lemmatizer = nltk.WordNetLemmatizer()\n",
    "    tokenization = nltk.word_tokenize(text)\n",
    "    \n",
    "    text1= []\n",
    "    for w in tokenization:\n",
    "        text1.append(wordnet_lemmatizer.lemmatize(w))\n",
    "    \n",
    "    text2 = ' '.join(text1)\n",
    "    \n",
    "    return text2\n",
    "\n",
    "#Function to remove stopwords ----------------------------------------------------------------\n",
    "def remove_stopwords(text):\n",
    "    \n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "#Inference and Classification -----------------------------------------------------------------\n",
    "def infer_tags(q, tfidf_vectorizer):\n",
    "    \n",
    "    q = clean_text(q)\n",
    "    q = remove_stopwords(q)\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    q_pred = loaded_model.predict(q_vec)\n",
    "\n",
    "    lt = multilabel_binarizer.inverse_transform(q_pred)\n",
    "\n",
    "    out = [item for t in lt for item in t]\n",
    "    \n",
    "    return out\n",
    "\n",
    "#NLP Tokens ------------------------------------------------------------------------------------\n",
    "def ner_text(text):\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(nlp._path)\n",
    "    \n",
    "    ner_tokens = []\n",
    "    doc = nlp(text)\n",
    "  \n",
    "    for ent in doc.ents:\n",
    "        ner_tokens.append(ent.text+\"->\"+ent.label_)\n",
    "\n",
    "    return ner_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918c42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert into Applicant DB ---------------------------------------------------------------------\n",
    "def insert_applicant_db(logindf_from_post):\n",
    "    \n",
    "    sqliteConnection = sqlite3.connect('Database\\job_applicants.db')\n",
    "    cursor = sqliteConnection.cursor()\n",
    "    \n",
    "    try:\n",
    "        df = pd.DataFrame([['#',str(logindf_from_post['name'][0]),\n",
    "                            logindf_from_post['number'][0],\n",
    "                          str(logindf_from_post['job_description'][0]),\n",
    "                          str(logindf_from_post['address'][0])]],\n",
    "                          columns=['uniq_id','name','number','job_description','address'])\n",
    "        \n",
    "        df.to_sql('job_applicants', sqliteConnection, if_exists='append', index = False)\n",
    "    \n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "    #Close DB        \n",
    "    if sqliteConnection:\n",
    "        sqliteConnection.close()\n",
    "        print('SQLite Connection to applicant DB closed')\n",
    "    \n",
    "    return\n",
    "\n",
    "#Insert into Login DB --------------------------------------------------------------------------\n",
    "def insert_login_db(logindf_from_post):\n",
    "    \n",
    "    sqliteConnection = sqlite3.connect('Database\\job_applicants_login.db')\n",
    "    cursor = sqliteConnection.cursor()\n",
    "    \n",
    "    #If name not in db\n",
    "    try:\n",
    "        df = pd.DataFrame([['#',str(logindf_from_post['name'][0]),\n",
    "                            str(logindf_from_post['password'][0])]], \n",
    "                          columns=['uniq_id','name','password'])\n",
    "        df.to_sql('job_applicants_login', sqliteConnection, if_exists='append', index = False)\n",
    "    \n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "    #Close DB        \n",
    "    if sqliteConnection:\n",
    "        sqliteConnection.close()\n",
    "        print('SQLite Connection to login DB closed')\n",
    "    \n",
    "    return\n",
    "\n",
    "#Login DB --------------------------------------------------------------------------------------\n",
    "def login_db(post_name):\n",
    "    \n",
    "    sqliteConnection = sqlite3.connect('Database\\job_applicants_login.db')\n",
    "    cursor = sqliteConnection.cursor()\n",
    "    \n",
    "    #If name not in db\n",
    "    try:\n",
    "        select_all = \"SELECT * FROM job_applicants_login WHERE name = '\"+post_name+\"'\"\n",
    "        info_from_db = cursor.execute(select_all).fetchall()\n",
    "        pass_df = pd.DataFrame(info_from_db, columns = ['uniq_id','name','password'])\n",
    "        pass_from_df = pass_df['password'][0]\n",
    "    \n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "    #Close DB        \n",
    "    if sqliteConnection:\n",
    "        sqliteConnection.close()\n",
    "        print('SQLite Connection to login DB closed')\n",
    "        \n",
    "    return pass_from_df\n",
    "\n",
    "#Applicant DB ----------------------------------------------------------------------------------\n",
    "def job_applicants_db(login_name_from_post):\n",
    "\n",
    "    sqliteConnection = sqlite3.connect('Database\\job_applicants.db')\n",
    "    cursor = sqliteConnection.cursor()\n",
    "    \n",
    "    select_all = \"SELECT * FROM job_applicants WHERE name = '\"+login_name_from_post+\"'\"\n",
    "    \n",
    "    rows = cursor.execute(select_all).fetchall()\n",
    "    \n",
    "    querydf = pd.DataFrame(rows, columns = ['uniq_id','name','number', 'job_description','address'])\n",
    "    \n",
    "    #Close DB\n",
    "    if sqliteConnection:\n",
    "        sqliteConnection.close()\n",
    "        print('SQLite Connection to applicants JD closed')\n",
    "        \n",
    "    return querydf\n",
    "\n",
    "#Job Description DB -------------------------------------------------------------------------------\n",
    "def job_description_db(prediction, inter_json):\n",
    "    \n",
    "    # Connect to DB and create a cursor\n",
    "    sqliteConnection = sqlite3.connect('Database\\job_description.db')\n",
    "    cursor = sqliteConnection.cursor()\n",
    "\n",
    "    # Fetch and output result\n",
    "    query = \"SELECT * FROM job_description WHERE category = '\"+prediction[0]+\"' LIMIT 2\"\n",
    "\n",
    "    rows = cursor.execute(str(query)).fetchall()\n",
    "\n",
    "    for r in rows:\n",
    "        inter_json.append({\"Unique_JD_ID\": r[0],\n",
    "                \"Job_Description\":r[1], \n",
    "                \"Category\": r[2]})\n",
    "\n",
    "    # Committing the changes\n",
    "    sqliteConnection.commit()\n",
    "\n",
    "    #Close DB\n",
    "    if sqliteConnection:\n",
    "        sqliteConnection.close()\n",
    "        print('SQLite Connection to JD DB closed')\n",
    "    \n",
    "    return inter_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f997036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to login DB closed\n",
      "Authenticated\n",
      "SQLite Connection to applicants JD closed\n",
      "C:\\Users\\XZ221DR\\Anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 13:42:38] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to JD DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 13:52:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to login DB closed\n",
      "  uniq_id        name      number  \\\n",
      "0       #  Jason Goel  9988456970   \n",
      "\n",
      "                                     job_description  \\\n",
      "0  About Us: Designerrs Lab provides a safe learn...   \n",
      "\n",
      "                        address  \n",
      "0  144 B, Bakers Street, London  \n",
      "SQLite Connection to applicant DB closed\n",
      "SQLite Connection to login DB closed\n",
      "Authenticated\n",
      "SQLite Connection to applicants JD closed\n",
      "C:\\Users\\XZ221DR\\Anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 13:52:28] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to JD DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 14:04:17] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [09/Feb/2023 14:04:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to login DB closed\n",
      "  uniq_id        name      number  \\\n",
      "0       #  Jason Goel  9988456970   \n",
      "\n",
      "                                     job_description  \\\n",
      "0  About Us: Designerrs Lab provides a safe learn...   \n",
      "\n",
      "                        address  \n",
      "0  144 B, Bakers Street, London  \n",
      "SQLite Connection to applicant DB closed\n",
      "SQLite Connection to login DB closed\n",
      "Authenticated\n",
      "SQLite Connection to applicants JD closed\n",
      "C:\\Users\\XZ221DR\\Anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.5.0\n",
      "SQLite Connection to JD DB closed\n",
      "C:\\Users\\XZ221DR\\Anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 14:04:38] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to JD DB closed\n",
      "SQLite Connection to login DB closed\n",
      "Authenticated\n",
      "SQLite Connection to applicants JD closed\n",
      "C:\\Users\\XZ221DR\\Anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.5.0\n",
      "SQLite Connection to JD DB closed\n",
      "C:\\Users\\XZ221DR\\Anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 14:06:15] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to JD DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 14:06:28] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Connection to login DB closed\n",
      "  uniq_id         name      number  \\\n",
      "0       #  Jasons Goel  9988456970   \n",
      "\n",
      "                                     job_description  \\\n",
      "0  Greetings from Amity University Position looki...   \n",
      "\n",
      "                        address  \n",
      "0  144 B, Bakers Street, London  \n",
      "SQLite Connection to applicant DB closed\n",
      "SQLite Connection to login DB closed\n",
      "Authenticated\n",
      "SQLite Connection to applicants JD closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Feb/2023 14:06:31] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XZ221DR\\Anaconda3\\lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.5.0\n",
      "SQLite Connection to JD DB closed\n"
     ]
    }
   ],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "\n",
    "def predict():\n",
    "    \n",
    "    #login DB ----------------------------------------------------------------------------------------------\n",
    "    sqliteConnection = sqlite3.connect('Database\\job_applicants_login.db')\n",
    "    cursor = sqliteConnection.cursor()\n",
    "    \n",
    "    json_ = request.json\n",
    "    logindf_from_post = pd.DataFrame(json_)\n",
    "    \n",
    "    #Get data from login db --------------------------------------------------------------------------------\n",
    "    try:\n",
    "        pass_from_df = login_db(logindf_from_post['name'][0])\n",
    "        if pass_from_df == '':\n",
    "            if logindf_from_post['register'][0] == 'yes':\n",
    "                #insert new user login\n",
    "                insert_login_db(logindf_from_post)\n",
    "                insert_applicant_db(logindf_from_post)\n",
    "                return jsonify([{\"Message\":\"Created new credentials. Please run the same POST again\"}])\n",
    "            return jsonify([{\"Message\":\"Unable to authenticate. User name does not exist. Please create new credentials.\"}])\n",
    "    #Handle Error\n",
    "    except sqlite3.Error as error:\n",
    "        print('Error occured connecting to login_db - ', error)\n",
    "    \n",
    "    login_name_from_post = logindf_from_post['name'][0]\n",
    "    passwrd_from_post = logindf_from_post['password'][0]\n",
    "    \n",
    "    #Password Authenticate ----------------------------------------------------------------------------------\n",
    "    if str(passwrd_from_post) == str(pass_from_df):\n",
    "        print(\"Authenticated\")\n",
    "    else:\n",
    "        print(\"Pass Incorrect\")\n",
    "        return jsonify([{\"Message\":\"Unable to authenticate. Please enter valid password.\"}])\n",
    "    \n",
    "    #Get data from applicants db -----------------------------------------------------------------------------\n",
    "    try:\n",
    "        querydf = job_applicants_db(login_name_from_post)\n",
    "    #Handle Error\n",
    "    except sqlite3.Error as error:\n",
    "        print('Error occured connecting to job_applicants_db - ', error)\n",
    "    \n",
    "    final_json = []\n",
    "    inter_json = []\n",
    "    \n",
    "    #Prediction ----------------------------------------------------------------------------------------------\n",
    "    for i, row in querydf.iterrows():\n",
    "        text = querydf['job_description'][i]\n",
    "        ids = querydf['uniq_id'][i]\n",
    "        name = querydf['name'][i]\n",
    "        number = querydf['number'][i]\n",
    "        address = querydf['address'][i]\n",
    "\n",
    "        ner_tokens = ner_text(text)\n",
    "\n",
    "        prediction = infer_tags(str(text),tfidf_vectorizer)\n",
    "        response = list(prediction)\n",
    "        \n",
    "        #If no prediction\n",
    "        if not response:\n",
    "            prediction = 'Unable categorize JD.'\n",
    "            response = [prediction]\n",
    "        \n",
    "        #Connect to job description db ----------------------------------------------------------------------\n",
    "        try:\n",
    "            inter_json = job_description_db(prediction, inter_json)\n",
    "        #Handle Error\n",
    "        except sqlite3.Error as error:\n",
    "            print('Error occured connecting to job_description_db - ', error)\n",
    "\n",
    "            \n",
    "        # Close DB Connection irrespective of success or failure ---------------------------------------------\n",
    "        finally:\n",
    "\n",
    "            if sqliteConnection:\n",
    "                sqliteConnection.close()\n",
    "\n",
    "            final_json.append({\"Unique_Applicant_ID\": str(ids),\n",
    "                                \"Name\": name,\n",
    "                                \"Phone Number\": str(number),\n",
    "                                \"Address\": address,\n",
    "                                \"Applicant_Job_Description\":text, \n",
    "                                \"Prediction\": response,\n",
    "                                \"NER_Tokens\": ner_tokens,\n",
    "                                \"Similar_Jobs\": inter_json})\n",
    "            \n",
    "            inter_json = []\n",
    "\n",
    "    return jsonify(final_json)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda5392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
